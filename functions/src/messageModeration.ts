import { onDocumentCreated } from 'firebase-functions/v2/firestore';
import { setGlobalOptions } from 'firebase-functions/v2';
import * as admin from 'firebase-admin';
import OpenAI from 'openai';

// Set global options for all functions
setGlobalOptions({
  region: 'us-central1',
  memory: '1GiB',
  timeoutSeconds: 30,
  maxInstances: 50
});

// Initialize Firebase Admin if not already initialized
if (!admin.apps.length) {
  admin.initializeApp();
}

// Initialize OpenAI
const openai = new OpenAI({
  apiKey: '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', 
});

/**
 * TypeScript Interfaces
 */
interface MessageData {
  body: string;
  senderCpId: string;
  groupId: string;
  createdAt: admin.firestore.Timestamp;
  attachments?: any;
  [key: string]: any;
}

interface UserProfile {
  userUID: string;
  locale?: 'arabic' | 'english';
  [key: string]: any;
}

interface LocalizedMessages {
  arabic: {
    [key: string]: string;
  };
  english: {
    [key: string]: string;
  };
}

interface ModerationStatus {
  status: 'pending' | 'approved' | 'blocked' | 'manual_review';
  reason: string | null;
}

interface OpenAIModerationResult {
  shouldBlock: boolean;
  violationType: 'social_media_sharing' | 'sexual_content' | 'cuckoldry_content' | 'homosexuality_content' | 'none';
  severity: 'low' | 'medium' | 'high';
  confidence: number;
  reason: string;
  detectedContent: string[];
  culturalContext?: string;
  processingTime?: number;
}

interface CharMapping {
  originalIndex: number;
  normalizedIndex: number;
}

interface NormalizedText {
  original: string;
  normalized: string;
  charMap: CharMapping[];
}

interface CustomRuleResult {
  detected: boolean;
  type: 'social_media_sharing' | 'sexual_content' | 'cuckoldry_content' | 'homosexuality_content';
  severity: 'low' | 'medium' | 'high';
  confidence: number;
  reason: string;
  detectedSpans: Array<{start: number; end: number; content: string}>;
}

interface FinalModerationDecision {
  action: 'block' | 'review' | 'allow_with_redaction' | 'allow';
  reason: string;
  violationType?: string;
  confidence: number;
  redactionSpans?: Array<{start: number; end: number}>;
  processingDetails: {
    openaiUsed: boolean;
    customRulesUsed: boolean;
    processingTime: number;
  };
}


/**
 * Localized violation messages
 */
const LOCALIZED_MESSAGES: LocalizedMessages = {
  arabic: {
    social_media_sharing: 'Ù…Ø´Ø§Ø±ÙƒØ© Ø­Ø³Ø§Ø¨Ø§Øª ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­Ø©',
    sexual_content: 'Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ù†Ø³ÙŠ ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­',
    cuckoldry_content: 'Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ø§Ù„Ù„Ø§Ø¦Ù‚ ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­',
    homosexuality_content: 'Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­',
    harassment: 'Ø§Ù„Ù…Ø¶Ø§ÙŠÙ‚Ø© ÙˆØ§Ù„ØªØ­Ø±Ø´ ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­',
    hate: 'Ø®Ø·Ø§Ø¨ Ø§Ù„ÙƒØ±Ø§Ù‡ÙŠØ© ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­',
    illicit: 'Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­',
    system_error: 'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… - ØªØ­Øª Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©',
    manual_review: 'Ø±Ø³Ø§Ù„ØªÙƒ ØªØ­Øª Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©'
  },
  english: {
    social_media_sharing: 'Sharing social media accounts is not allowed',
    sexual_content: 'Sexual content is not allowed',
    cuckoldry_content: 'Inappropriate sexual content is not allowed',
    homosexuality_content: 'Inappropriate content is not allowed',
    harassment: 'Harassment content is not allowed',
    hate: 'Hate speech is not allowed',
    illicit: 'Illicit content is not allowed',
    system_error: 'System error - under review',
    manual_review: 'Your message is under review by moderators'
  }
};


/**
 * Normalize Arabic text with character index mapping
 * Step 1: Remove diacritics, zero-width chars, tatweel, unify letters, convert numbers, collapse spaces
 */
function normalizeArabicText(text: string): NormalizedText {
  console.log('ğŸ”§ Starting Arabic text normalization...');
  
  const original = text;
  const charMap: CharMapping[] = [];
  let normalized = '';
  let normalizedIndex = 0;

  for (let i = 0; i < original.length; i++) {
    const char = original[i];
    let processedChar = char;

    // Remove diacritics (Arabic diacritical marks)
    if (/[\u064B-\u065F\u0670\u0671]/.test(char)) {
      // Skip diacritics - don't add to normalized text
      continue;
    }

    // Remove zero-width characters
    if (/[\u200B-\u200F\u2060\u2061\u2062\u2063\u2064\u2065\u2066\u2067\u2068\u2069\u061C]/.test(char)) {
      // Skip zero-width chars
      continue;
    }

    // Remove Arabic tatweel (kashida)
    if (char === '\u0640') {
      continue;
    }

    // Unify Arabic letters
    // Alif variations: Ø£Ø¥Ø¢ â†’ Ø§
    if (/[Ø£Ø¥Ø¢]/.test(char)) {
      processedChar = 'Ø§';
    }
    // Ya variations: Ù‰ â†’ ÙŠ
    else if (char === 'Ù‰') {
      processedChar = 'ÙŠ';
    }
    // Ta marbuta: Ø© â†’ Ù‡ (optional normalization)
    else if (char === 'Ø©') {
      processedChar = 'Ù‡';
    }

    // Convert Arabic-Indic digits to Western digits
    const arabicToWestern: {[key: string]: string} = {
      'Ù ': '0', 'Ù¡': '1', 'Ù¢': '2', 'Ù£': '3', 'Ù¤': '4',
      'Ù¥': '5', 'Ù¦': '6', 'Ù§': '7', 'Ù¨': '8', 'Ù©': '9'
    };
    if (arabicToWestern[char]) {
      processedChar = arabicToWestern[char];
    }

    // Add character mapping
    charMap.push({
      originalIndex: i,
      normalizedIndex: normalizedIndex
    });

    normalized += processedChar;
    normalizedIndex++;
  }

  // Collapse extra spaces and punctuation
  normalized = normalized
    .replace(/\s+/g, ' ') // Multiple spaces to single space
    .replace(/[.]{2,}/g, '.') // Multiple dots to single dot
    .replace(/[!]{2,}/g, '!') // Multiple exclamations to single
    .replace(/[?]{2,}/g, '?') // Multiple questions to single
    .trim();

  console.log(`âœ… Normalization complete: ${original.length} â†’ ${normalized.length} chars`);
  
  return {
    original,
    normalized,
    charMap
  };
}

/**
 * De-obfuscate common tokens (platform names, handles, etc.)
 * Step 2: Collapse spaced/dotted platform names and handles
 */
function deobfuscateTokens(text: string): string {
  console.log('ğŸ•µï¸ Starting token de-obfuscation...');
  
  let deobfuscated = text;

  // Platform names with spaces/dots
  const platformPatterns = [
    // English platforms with spaces/dots
    { pattern: /w\s*a\s*\.\s*m\s*e/gi, replacement: 'wa.me' },
    { pattern: /i\s*n\s*s\s*t\s*a\s*g\s*r\s*a\s*m/gi, replacement: 'instagram' },
    { pattern: /f\s*a\s*c\s*e\s*b\s*o\s*o\s*k/gi, replacement: 'facebook' },
    { pattern: /w\s*h\s*a\s*t\s*s\s*a\s*p\s*p/gi, replacement: 'whatsapp' },
    { pattern: /t\s*e\s*l\s*e\s*g\s*r\s*a\s*m/gi, replacement: 'telegram' },
    { pattern: /t\s*i\s*k\s*t\s*o\s*k/gi, replacement: 'tiktok' },
    { pattern: /s\s*n\s*a\s*p\s*c\s*h\s*a\s*t/gi, replacement: 'snapchat' },
    
    // Arabic platforms with spaces
    { pattern: /Øª\s*Ù„\s*ÙŠ\s*Ø¬\s*Ø±\s*Ø§\s*Ù…/g, replacement: 'ØªÙ„ÙŠØ¬Ø±Ø§Ù…' },
    { pattern: /Ø§\s*Ù†\s*Ø³\s*Øª\s*Ù‚\s*Ø±\s*Ø§\s*Ù…/g, replacement: 'Ø§Ù†Ø³ØªÙ‚Ø±Ø§Ù…' },
    { pattern: /Ø§\s*Ù†\s*Ø³\s*Øª\s*Ø§/g, replacement: 'Ø§Ù†Ø³ØªØ§' },
    { pattern: /Ù\s*ÙŠ\s*Ø³\s*Ø¨\s*Ùˆ\s*Ùƒ/g, replacement: 'ÙÙŠØ³Ø¨ÙˆÙƒ' },
    { pattern: /Ùˆ\s*Ø§\s*Øª\s*Ø³\s*Ø§\s*Ø¨/g, replacement: 'ÙˆØ§ØªØ³Ø§Ø¨' },
    { pattern: /Ø³\s*Ù†\s*Ø§\s*Ø¨\s*Ø´\s*Ø§\s*Øª/g, replacement: 'Ø³Ù†Ø§Ø¨ Ø´Ø§Øª' },
    { pattern: /Øª\s*ÙŠ\s*Ùƒ\s*Øª\s*Ùˆ\s*Ùƒ/g, replacement: 'ØªÙŠÙƒ ØªÙˆÙƒ' },
  ];

  // Apply platform de-obfuscation
  for (const { pattern, replacement } of platformPatterns) {
    deobfuscated = deobfuscated.replace(pattern, replacement);
  }

  // Handle spaced @ mentions: @ a m j a d â†’ @amjad
  deobfuscated = deobfuscated.replace(/@\s+([a-zA-Z0-9_]+(?:\s+[a-zA-Z0-9_]+)*)/g, (match, username) => {
    const cleanUsername = username.replace(/\s+/g, '');
    return `@${cleanUsername}`;
  });

  // Handle spaced usernames without @
  deobfuscated = deobfuscated.replace(/\b([a-zA-Z0-9_]+(?:\s+[a-zA-Z0-9_]+){2,})\b/g, (match) => {
    // Only if it looks like a username (3+ parts, alphanumeric)
    const parts = match.split(/\s+/);
    if (parts.length >= 3 && parts.every(part => /^[a-zA-Z0-9_]+$/.test(part))) {
      return parts.join('');
    }
    return match;
  });

  // Handle dotted domains: wa . me â†’ wa.me
  deobfuscated = deobfuscated.replace(/\b([a-zA-Z0-9]+(?:\s*\.\s*[a-zA-Z0-9]+)+)\b/g, (match) => {
    return match.replace(/\s*\.\s*/g, '.');
  });

  console.log('âœ… Token de-obfuscation complete');
  return deobfuscated;
}

/**
 * Custom rule patterns for Arabic content (applied to normalized text)
 */
const CUSTOM_RULE_PATTERNS = {
  socialMedia: {
    platforms: [
      'Ø§Ù†Ø³ØªÙ‚Ø±Ø§Ù…', 'Ø§Ù†Ø³ØªØ§', 'instagram', 'insta',
      'ÙÙŠØ³Ø¨ÙˆÙƒ', 'ÙÙŠØ³', 'facebook', 'fb',
      'ØªÙŠÙƒ ØªÙˆÙƒ', 'tiktok',
      'Ø³Ù†Ø§Ø¨ Ø´Ø§Øª', 'Ø³Ù†Ø§Ø¨', 'snapchat', 'snap',
      'ÙˆØ§ØªØ³Ø§Ø¨', 'whatsapp', 'ÙˆØ§ØªØ³',
      'ØªÙ„ÙŠØ¬Ø±Ø§Ù…', 'telegram',
      'wa.me', 'Ø­Ø³Ø§Ø¨', 'Ø§ÙƒØ§ÙˆÙ†Øª', 'account'
    ],
    followPhrases: [
      'ØªØ§Ø¨Ø¹ÙˆÙ†ÙŠ Ø¹Ù„Ù‰', 'Ø¶ÙŠÙÙˆÙ†ÙŠ Ø¹Ù„Ù‰', 'Ø§ÙƒØ§ÙˆÙ†ØªÙŠ Ø¹Ù„Ù‰', 'Ø­Ø³Ø§Ø¨ÙŠ ÙÙŠ',
      'Ø´ÙˆÙÙˆÙ†ÙŠ Ø¹Ù„Ù‰', 'Ù„Ù‚ÙˆÙ†ÙŠ Ø¹Ù„Ù‰', 'follow me on', 'add me on',
      'Ù…Ù…ÙƒÙ† Ù†ØªÙˆØ§ØµÙ„', 'Ù†ØªÙˆØ§ØµÙ„ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£Ø®Ø±Ù‰', 'Ù†ØªÙƒÙ„Ù… ÙÙŠ Ù…ÙƒØ§Ù† Ø¢Ø®Ø±'
    ],
    usernamePatterns: [
      /@[a-zA-Z0-9_.]+/,
      /[a-zA-Z0-9_.]+\.(com|net|org|me)/,
      /\b[a-zA-Z0-9_.]{3,}\b/
    ]
  },
  sexual: {
    explicit: [
      'Ø¬Ù†Ø³', 'Ø¹Ø±ÙŠ', 'Ø¥Ø¨Ø§Ø­ÙŠ', 'sex', 'porn', 'nude',
      'Ø²Ø¨', 'ÙƒØ³', 'Ù†ÙŠÙƒ', 'Ø·ÙŠØ²', 'Ø³Ø§Ù„Ø¨', 'Ù…ÙˆØ¬Ø¨'
    ]
  },
  cuckoldry: {
    terms: ['Ø¯ÙŠÙˆØ«', 'Ù‚ÙˆØ§Ø¯', 'ÙŠØ´Ø§Ø±Ùƒ Ø²ÙˆØ¬ØªÙ‡', 'ØªØ¨Ø§Ø¯Ù„ Ø²ÙˆØ¬Ø§Øª']
  },
  homosexuality: {
    terms: ['Ø´Ø§Ø°', 'Ø´Ø°ÙˆØ°', 'Ù…Ø«Ù„ÙŠ', 'Ù„ÙˆØ·ÙŠ', 'Ø®Ù†ÙŠØ«', 'gay', 'lesbian']
  }
};

/**
 * Detect message language based on character analysis
 */
function detectMessageLanguage(text: string): 'arabic' | 'english' {
  console.log('ğŸŒ Detecting message language...');
  
  // Count Arabic characters (including Arabic letters and Arabic-specific punctuation)
  const arabicCharsRegex = /[\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF]/g;
  const arabicMatches = text.match(arabicCharsRegex);
  const arabicCharCount = arabicMatches ? arabicMatches.length : 0;
  
  // Count English characters
  const englishCharsRegex = /[a-zA-Z]/g;
  const englishMatches = text.match(englishCharsRegex);
  const englishCharCount = englishMatches ? englishMatches.length : 0;
  
  // Calculate total meaningful characters
  const totalChars = arabicCharCount + englishCharCount;
  
  if (totalChars === 0) {
    console.log('âš ï¸ No meaningful characters detected, defaulting to Arabic');
    return 'arabic';
  }
  
  // Calculate Arabic percentage
  const arabicPercentage = (arabicCharCount / totalChars) * 100;
  
  console.log(`ğŸ“Š Language detection: Arabic: ${arabicCharCount} chars (${arabicPercentage.toFixed(1)}%), English: ${englishCharCount} chars`);
  
  // If 30% or more Arabic characters, consider it Arabic
  const detectedLanguage = arabicPercentage >= 30 ? 'arabic' : 'english';
  console.log(`ğŸŒ Detected language: ${detectedLanguage}`);
  
  return detectedLanguage;
}

/**
 * Moderation prompts for different languages
 */
const MODERATION_PROMPTS = {
  arabic: `Ø£Ù†Øª Ù†Ø¸Ø§Ù… Ù…Ø±Ø§Ù‚Ø¨Ø© Ù…Ø­ØªÙˆÙ‰ Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. Ù…Ù‡Ù…ØªÙƒ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±ÙÙ‚ ÙˆØ§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ù…Ø®Ø§Ù„ÙØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ÙÙ‚Ø·:

**Ø§Ù„Ù…Ø®Ø§Ù„ÙØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø±ØµØ¯Ù‡Ø§:**

1. **Ù…Ø´Ø§Ø±ÙƒØ© Ø­Ø³Ø§Ø¨Ø§Øª ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ** 
   - Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ø¨Ø§Ø±Ø§Øª Ù…Ø«Ù„: "ØªØ§Ø¨Ø¹ÙˆÙ†ÙŠ Ø¹Ù„Ù‰"ØŒ "Ø¶ÙŠÙÙˆÙ†ÙŠ Ø¹Ù„Ù‰"ØŒ "Ø­Ø³Ø§Ø¨ÙŠ ÙÙŠ"ØŒ "Ø§ÙƒØ§ÙˆÙ†ØªÙŠ Ø¹Ù„Ù‰"
   - Ø°ÙƒØ± Ù…Ù†ØµØ§Øª Ù…Ø«Ù„: Ø§Ù†Ø³ØªÙ‚Ø±Ø§Ù…ØŒ ÙÙŠØ³Ø¨ÙˆÙƒØŒ ØªÙŠÙƒ ØªÙˆÙƒØŒ Ø³Ù†Ø§Ø¨ Ø´Ø§ØªØŒ ÙˆØ§ØªØ³Ø§Ø¨ØŒ ØªÙ„ÙŠØ¬Ø±Ø§Ù…
   - Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ Ù…Ø«Ù„: "Ù…Ù…ÙƒÙ† Ù†ØªÙˆØ§ØµÙ„ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£Ø®Ø±Ù‰"ØŒ "Ù†ØªÙƒÙ„Ù… ÙÙŠ Ù…ÙƒØ§Ù† Ø¢Ø®Ø±"
   - Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø£Ùˆ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø£Ùˆ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡Ø©

2. **Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ù†Ø³ÙŠ Ø£Ùˆ Ø§Ù„Ø¥Ø¨Ø§Ø­ÙŠ**
   - Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØµØ±ÙŠØ­Ø© ÙˆØ§Ù„Ø£Ù„ÙØ§Ø¸ Ø§Ù„Ø¬Ù†Ø³ÙŠØ© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©
   - Ø§Ù„Ø¥ÙŠØ­Ø§Ø¡Ø§Øª Ø§Ù„Ø¬Ù†Ø³ÙŠØ© ÙˆØ§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø«ÙŠØ±Ø©
   - Ø·Ù„Ø¨ ØµÙˆØ± Ø£Ùˆ Ù„Ù‚Ø§Ø¡Ø§Øª Ø®Ø§ØµØ©
   - Ø£ÙŠ Ù…Ø­ØªÙˆÙ‰ Ø¬Ù†Ø³ÙŠ ØºÙŠØ± Ù„Ø§Ø¦Ù‚

3. **Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¯ÙŠÙˆØ«Ø© ÙˆØªØ¨Ø§Ø¯Ù„ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬**
   - ÙƒÙ„Ù…Ø§Øª Ù…Ø«Ù„: "Ø¯ÙŠÙˆØ«"ØŒ "Ù‚ÙˆØ§Ø¯"ØŒ "ÙŠØ´Ø§Ø±Ùƒ Ø²ÙˆØ¬ØªÙ‡"ØŒ "ØªØ¨Ø§Ø¯Ù„ Ø²ÙˆØ¬Ø§Øª"
   - Ø£ÙŠ Ù…Ø­ØªÙˆÙ‰ ÙŠØªØ¹Ù„Ù‚ Ø¨Ø§Ù„Ø¯ÙŠÙˆØ«Ø© Ø£Ùˆ Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© Ø§Ù„Ø¬Ù†Ø³ÙŠØ©
   - Ø¹Ø¨Ø§Ø±Ø§Øª ØªØ¯Ù„ Ø¹Ù„Ù‰ ØªØ¨Ø§Ø¯Ù„ Ø§Ù„Ø´Ø±ÙƒØ§Ø¡

4. **Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø«Ù„ÙŠ Ø£Ùˆ Ø§Ù„Ø´Ø§Ø° Ø¬Ù†Ø³ÙŠØ§Ù‹**
   - ÙƒÙ„Ù…Ø§Øª Ù…Ø«Ù„: "Ø´Ø§Ø°"ØŒ "Ù…Ø«Ù„ÙŠ"ØŒ "Ù„ÙˆØ·ÙŠ"ØŒ "Ø®Ù†ÙŠØ«" 
   - Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø´Ø±ÙƒØ§Ø¡ Ù…Ù† Ù†ÙØ³ Ø§Ù„Ø¬Ù†Ø³
   - Ø£ÙŠ Ù…Ø­ØªÙˆÙ‰ ÙŠØ±ÙˆØ¬ Ù„Ù„Ø´Ø°ÙˆØ° Ø§Ù„Ø¬Ù†Ø³ÙŠ

**Ø¥Ø±Ø´Ø§Ø¯Ø§Øª Ù…Ù‡Ù…Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„:**
- Ø§Ù†ØªØ¨Ù‡ Ù„Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø«Ù‚Ø§ÙÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙˆØ§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠ
- ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ù†Ù‚Ø§Ø´ Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ Ø§Ù„Ù…Ø­ØªØ±Ù… (Ù…Ø³Ù…ÙˆØ­) ÙˆØ§Ù„Ø¨Ø­Ø« Ø§Ù„Ø´Ø®ØµÙŠ Ø§Ù„Ù…Ø®Ø§Ù„Ù (Ù…Ù…Ù†ÙˆØ¹)
- Ø±Ø§Ø¹ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¨Ø¯ÙŠÙ„Ø© Ø£Ùˆ Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø© Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø±Ù‚Ø§Ø¨Ø©
- Ø§Ù†ØªØ¨Ù‡ Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ù‚Ø³Ù…Ø© Ø¨Ù…Ø³Ø§ÙØ§Øª Ø£Ùˆ Ø±Ù…ÙˆØ²
- Ø§Ø¹ØªØ¨Ø± Ø´Ø¯Ø© Ø§Ù„Ù…Ø®Ø§Ù„ÙØ© (Ø®ÙÙŠÙØ©ØŒ Ù…ØªÙˆØ³Ø·Ø©ØŒ Ø¹Ø§Ù„ÙŠØ©)

**Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„Ù‡:**
"{{MESSAGE_TEXT}}"

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ:**
Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø· Ø¯ÙˆÙ† Ø£ÙŠ Ù†Øµ Ø¥Ø¶Ø§ÙÙŠ:

{
  "shouldBlock": true/false,
  "violationType": "social_media_sharing" Ø£Ùˆ "sexual_content" Ø£Ùˆ "cuckoldry_content" Ø£Ùˆ "homosexuality_content" Ø£Ùˆ "none",
  "severity": "low" Ø£Ùˆ "medium" Ø£Ùˆ "high",
  "confidence": 0.0-1.0,
  "reason": "Ø´Ø±Ø­ Ù…Ø®ØªØµØ± Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ø³Ø¨Ø¨ Ø§Ù„Ù‚Ø±Ø§Ø±",
  "detectedContent": ["Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø£Ùˆ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø®Ø§Ù„ÙØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©"],
  "culturalContext": "Ù…Ù„Ø§Ø­Ø¸Ø© Ø¹Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø«Ù‚Ø§ÙÙŠ Ø¥Ù† ÙˆØ¬Ø¯"
}`,

  english: `You are a content moderation system specialized in analyzing messages. Your task is to analyze the provided text and detect the following violations only:

**Required Violation Detection:**

1. **Social Media Account Sharing**
   - Look for phrases like: "follow me on", "add me on", "my account on", "find me on"
   - Platform mentions: Instagram, Facebook, TikTok, Snapchat, WhatsApp, Telegram
   - External communication attempts: "let's talk elsewhere", "contact me privately"
   - Usernames, links, or suspicious sharing patterns

2. **Sexual or Pornographic Content**
   - Explicit sexual words and direct sexual language
   - Sexual innuendos and suggestive phrases
   - Requests for photos or private meetings
   - Any inappropriate sexual content

3. **Cuckoldry and Partner Swapping Content**
   - Words like: "cuckold", "hotwife", "wife sharing", "partner swapping"
   - Any content related to cuckoldry or sexual pimping
   - Expressions indicating partner exchange

4. **Homosexual or LGBTQ+ Content**
   - Words like: "gay", "lesbian", "queer", seeking same-sex partners
   - Looking for same-gender partners
   - Any content promoting LGBTQ+ relationships

**Important Analysis Guidelines:**
- Consider cultural and religious context (Islamic/Arab culture)
- Distinguish between respectful academic discussion (allowed) vs. personal seeking (forbidden)
- Watch for character substitution to avoid detection
- Pay attention to words separated by spaces or symbols
- Consider violation severity (low, medium, high)

**Text to Analyze:**
"{{MESSAGE_TEXT}}"

**Required Response:**
Respond with JSON only, no additional text:

{
  "shouldBlock": true/false,
  "violationType": "social_media_sharing" or "sexual_content" or "cuckoldry_content" or "homosexuality_content" or "none",
  "severity": "low" or "medium" or "high",
  "confidence": 0.0-1.0,
  "reason": "Brief explanation in English for the decision",
  "detectedContent": ["List of detected violating phrases or words"],
  "culturalContext": "Note about cultural context if applicable"
}`
};

/**
 * Get user locale from community profile
 */
async function getUserLocale(senderCpId: string): Promise<'arabic' | 'english'> {
  try {
    console.log('ğŸŒ Getting user locale for:', senderCpId);
    
    const profileDoc = await admin.firestore()
      .collection('community_profiles')
      .doc(senderCpId)
      .get();
    
    if (!profileDoc.exists) {
      console.log('âš ï¸ Community profile not found, defaulting to Arabic');
      return 'arabic';
    }
    
    const profileData = profileDoc.data() as UserProfile;
    const userUID = profileData.userUID;
    
    if (!userUID) {
      console.log('âš ï¸ UserUID not found, defaulting to Arabic');
      return 'arabic';
    }
    
    // Get user document to check locale
    const userDoc = await admin.firestore()
      .collection('users')
      .doc(userUID)
      .get();
    
    if (!userDoc.exists) {
      console.log('âš ï¸ User document not found, defaulting to Arabic');
      return 'arabic';
    }
    
    const userData = userDoc.data();
    const locale = userData?.locale || 'arabic';
    
    console.log('ğŸŒ User locale determined:', locale);
    return locale === 'english' ? 'english' : 'arabic';
    
  } catch (error) {
    console.error('âŒ Error getting user locale:', error);
    return 'arabic'; // Default to Arabic
  }
}

/**
 * Get localized violation message
 */
function getLocalizedMessage(violationType: string, locale: 'arabic' | 'english'): string {
  const messages = LOCALIZED_MESSAGES[locale];
  return messages[violationType] || messages.system_error;
}

/**
 * Evaluate custom rules on normalized text
 * Step 5: For each rule, detect â†’ check intent â†’ assign severity/confidence
 */
function evaluateCustomRules(normalizedText: string): CustomRuleResult[] {
  console.log('ğŸ” Evaluating custom rules on normalized text...');
  
  const results: CustomRuleResult[] = [];
  const lowerText = normalizedText.toLowerCase();

  // Social Media Sharing Rules
  console.log('ğŸ“± Checking social media sharing rules...');
  const socialMediaSpans: Array<{start: number; end: number; content: string}> = [];
  let socialMediaSeverity: 'low' | 'medium' | 'high' = 'low';
  let socialMediaConfidence = 0;

  // Check for follow phrases
  for (const phrase of CUSTOM_RULE_PATTERNS.socialMedia.followPhrases) {
    const phraseIndex = lowerText.indexOf(phrase.toLowerCase());
    if (phraseIndex !== -1) {
      socialMediaSpans.push({
        start: phraseIndex,
        end: phraseIndex + phrase.length,
        content: phrase
      });
      socialMediaSeverity = 'high';
      socialMediaConfidence = Math.max(socialMediaConfidence, 0.9);
    }
  }

  // Check for platform mentions
  for (const platform of CUSTOM_RULE_PATTERNS.socialMedia.platforms) {
    const platformIndex = lowerText.indexOf(platform.toLowerCase());
    if (platformIndex !== -1) {
      socialMediaSpans.push({
        start: platformIndex,
        end: platformIndex + platform.length,
        content: platform
      });
      socialMediaSeverity = socialMediaSeverity === 'high' ? 'high' : 'medium';
      socialMediaConfidence = Math.max(socialMediaConfidence, 0.7);
    }
  }

  // Check for username patterns
  for (const pattern of CUSTOM_RULE_PATTERNS.socialMedia.usernamePatterns) {
    const matches = normalizedText.matchAll(new RegExp(pattern, 'gi'));
    for (const match of matches) {
      if (match.index !== undefined) {
        socialMediaSpans.push({
          start: match.index,
          end: match.index + match[0].length,
          content: match[0]
        });
        socialMediaSeverity = socialMediaSeverity === 'high' ? 'high' : 'medium';
        socialMediaConfidence = Math.max(socialMediaConfidence, 0.6);
      }
    }
  }

  if (socialMediaSpans.length > 0) {
    results.push({
      detected: true,
      type: 'social_media_sharing',
      severity: socialMediaSeverity,
      confidence: socialMediaConfidence,
      reason: `Detected social media sharing indicators: ${socialMediaSpans.map(s => s.content).join(', ')}`,
      detectedSpans: socialMediaSpans
    });
  }

  // Sexual Content Rules
  console.log('ğŸ” Checking sexual content rules...');
  const sexualSpans: Array<{start: number; end: number; content: string}> = [];
  let sexualConfidence = 0;

  for (const term of CUSTOM_RULE_PATTERNS.sexual.explicit) {
    const termIndex = lowerText.indexOf(term.toLowerCase());
    if (termIndex !== -1) {
      sexualSpans.push({
        start: termIndex,
        end: termIndex + term.length,
        content: term
      });
      sexualConfidence = Math.max(sexualConfidence, 0.95);
    }
  }

  if (sexualSpans.length > 0) {
    results.push({
      detected: true,
      type: 'sexual_content',
      severity: 'high',
      confidence: sexualConfidence,
      reason: `Detected explicit sexual content: ${sexualSpans.map(s => s.content).join(', ')}`,
      detectedSpans: sexualSpans
    });
  }

  // Cuckoldry Content Rules
  console.log('ğŸš« Checking cuckoldry content rules...');
  const cuckoldrySpans: Array<{start: number; end: number; content: string}> = [];
  let cuckoldryConfidence = 0;

  for (const term of CUSTOM_RULE_PATTERNS.cuckoldry.terms) {
    const termIndex = lowerText.indexOf(term.toLowerCase());
    if (termIndex !== -1) {
      cuckoldrySpans.push({
        start: termIndex,
        end: termIndex + term.length,
        content: term
      });
      cuckoldryConfidence = Math.max(cuckoldryConfidence, 0.9);
    }
  }

  if (cuckoldrySpans.length > 0) {
    results.push({
      detected: true,
      type: 'cuckoldry_content',
      severity: 'high',
      confidence: cuckoldryConfidence,
      reason: `Detected cuckoldry content: ${cuckoldrySpans.map(s => s.content).join(', ')}`,
      detectedSpans: cuckoldrySpans
    });
  }

  // Homosexuality Content Rules
  console.log('ğŸ³ï¸â€ğŸŒˆ Checking homosexuality content rules...');
  const homosexualitySpans: Array<{start: number; end: number; content: string}> = [];
  let homosexualityConfidence = 0;

  for (const term of CUSTOM_RULE_PATTERNS.homosexuality.terms) {
    const termIndex = lowerText.indexOf(term.toLowerCase());
    if (termIndex !== -1) {
      homosexualitySpans.push({
        start: termIndex,
        end: termIndex + term.length,
        content: term
      });
      homosexualityConfidence = Math.max(homosexualityConfidence, 0.9);
    }
  }

  if (homosexualitySpans.length > 0) {
    results.push({
      detected: true,
      type: 'homosexuality_content',
      severity: 'high',
      confidence: homosexualityConfidence,
      reason: `Detected inappropriate content: ${homosexualitySpans.map(s => s.content).join(', ')}`,
      detectedSpans: homosexualitySpans
    });
  }

  console.log(`âœ… Custom rule evaluation complete: ${results.length} violations detected`);
  return results;
}

/**
 * Map normalized text spans back to original text indices
 * Step 7: Map spans back to original indices using char-index map
 */
function mapSpansToOriginal(
  normalizedSpans: Array<{start: number; end: number}>, 
  charMap: CharMapping[]
): Array<{start: number; end: number}> {
  console.log('ğŸ—ºï¸ Mapping normalized spans back to original indices...');
  
  const originalSpans: Array<{start: number; end: number}> = [];

  for (const span of normalizedSpans) {
    // Find the original indices for start and end positions
    const startMapping = charMap.find(m => m.normalizedIndex === span.start);
    const endMapping = charMap.find(m => m.normalizedIndex === span.end - 1);

    if (startMapping && endMapping) {
      originalSpans.push({
        start: startMapping.originalIndex,
        end: endMapping.originalIndex + 1 // +1 to make it exclusive end
      });
    }
  }

  console.log(`âœ… Mapped ${normalizedSpans.length} spans to original indices`);
  return originalSpans;
}

/**
 * Synthesize final moderation decision with fixed precedence
 * Step 6: block > review > allow_with_redaction > allow
 */
function synthesizeDecision(
  openaiResult: OpenAIModerationResult,
  customRuleResults: CustomRuleResult[],
  processingTime: number
): FinalModerationDecision {
  console.log('âš–ï¸ Synthesizing final moderation decision...');
  
  // Hard-stop policy: Check OpenAI high-confidence violations first
  if (openaiResult.shouldBlock && (openaiResult.confidence >= 0.8 || openaiResult.severity === 'high')) {
    console.log('ğŸš« HARD STOP: High-confidence/severity OpenAI violation');
    return {
      action: 'block',
      reason: `OpenAI detected: ${openaiResult.reason}`,
      violationType: openaiResult.violationType,
      confidence: openaiResult.confidence,
      processingDetails: {
        openaiUsed: true,
        customRulesUsed: true,
        processingTime
      }
    };
  }

  // Check custom rules for high-severity violations
  const highSeverityRules = customRuleResults.filter(r => r.detected && r.severity === 'high');
  if (highSeverityRules.length > 0) {
    const highestConfidenceRule = highSeverityRules.reduce((max, rule) => 
      rule.confidence > max.confidence ? rule : max
    );

    if (highestConfidenceRule.confidence >= 0.9) {
      console.log('ğŸš« BLOCK: High-severity custom rule violation');
      return {
        action: 'block',
        reason: highestConfidenceRule.reason,
        violationType: highestConfidenceRule.type,
        confidence: highestConfidenceRule.confidence,
        processingDetails: {
          openaiUsed: true,
          customRulesUsed: true,
          processingTime
        }
      };
    }
  }

  // Check for review-worthy violations
  if (openaiResult.shouldBlock && (openaiResult.confidence >= 0.5 || openaiResult.severity === 'medium')) {
    console.log('âš ï¸ REVIEW: Medium-confidence/severity OpenAI violation');
    return {
      action: 'review',
      reason: `Requires review: ${openaiResult.reason}`,
      violationType: openaiResult.violationType,
      confidence: openaiResult.confidence,
      processingDetails: {
        openaiUsed: true,
        customRulesUsed: true,
        processingTime
      }
    };
  }

  const mediumSeverityRules = customRuleResults.filter(r => r.detected && (r.severity === 'medium' || r.severity === 'high'));
  if (mediumSeverityRules.length > 0) {
    const highestConfidenceRule = mediumSeverityRules.reduce((max, rule) => 
      rule.confidence > max.confidence ? rule : max
    );

    if (highestConfidenceRule.confidence >= 0.6) {
      console.log('âš ï¸ REVIEW: Custom rule requires review');
      return {
        action: 'review',
        reason: highestConfidenceRule.reason,
        violationType: highestConfidenceRule.type,
        confidence: highestConfidenceRule.confidence,
        processingDetails: {
          openaiUsed: true,
          customRulesUsed: true,
          processingTime
        }
      };
    }
  }

  // Check for redaction-worthy violations
  const lowSeverityRules = customRuleResults.filter(r => r.detected && r.severity === 'low');
  if (lowSeverityRules.length > 0) {
    console.log('âœï¸ ALLOW WITH REDACTION: Low-severity violations detected');
    
    const allSpans = lowSeverityRules.flatMap(rule => rule.detectedSpans);
    const redactionSpans = allSpans.map(span => ({ start: span.start, end: span.end }));

    return {
      action: 'allow_with_redaction',
      reason: `Content allowed with redaction of: ${lowSeverityRules.map(r => r.type).join(', ')}`,
      confidence: 0.7,
      redactionSpans,
      processingDetails: {
        openaiUsed: true,
        customRulesUsed: true,
        processingTime
      }
    };
  }

  // Default: Allow
  console.log('âœ… ALLOW: No significant violations detected');
  return {
    action: 'allow',
    reason: 'Content appears acceptable',
    confidence: 1.0 - Math.max(openaiResult.confidence || 0, 0.3),
    processingDetails: {
      openaiUsed: true,
      customRulesUsed: true,
      processingTime
    }
  };
}


/**
 * Analyze content using OpenAI Chat Completions with custom prompts
 */
async function checkWithOpenAI(text: string): Promise<OpenAIModerationResult> {
  console.log('ğŸ¤– Starting OpenAI analysis with custom prompts...');
  
  try {
    // Step 1: Detect message language
    const detectedLanguage = detectMessageLanguage(text);
    console.log(`ğŸ“¤ Using ${detectedLanguage} prompt for analysis`);
    
    // Step 2: Get appropriate prompt and prepare it
    const promptTemplate = MODERATION_PROMPTS[detectedLanguage];
    const prompt = promptTemplate.replace('{{MESSAGE_TEXT}}', text);
    
    const startTime = Date.now();
    
    // Step 3: Send request to Chat Completions API
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini', // Cost-effective model with good Arabic support
      messages: [
        {
          role: 'system',
          content: 'You are a content moderation expert. Always respond with valid JSON only, no additional text or formatting.'
        },
        {
          role: 'user',
          content: prompt
        }
      ],
      temperature: 0.1, // Low temperature for consistent results
      max_tokens: 500,   // Enough for JSON response
      response_format: { type: 'json_object' } // Ensure JSON response
    });
    
    const processingTime = Date.now() - startTime;
    console.log(`â±ï¸ OpenAI processing completed in ${processingTime}ms`);
    
    // Step 4: Parse the response
    const responseContent = completion.choices[0]?.message?.content;
    if (!responseContent) {
      throw new Error('Empty response from OpenAI');
    }
    
    console.log('ğŸ¤– Raw OpenAI Response:', responseContent);
    
    // Step 5: Parse JSON response
    let parsedResponse: any;
    try {
      parsedResponse = JSON.parse(responseContent);
    } catch (parseError) {
      console.error('âŒ Failed to parse OpenAI JSON response:', parseError);
      console.error('Raw response:', responseContent);
      throw new Error('Invalid JSON response from OpenAI');
    }
    
    // Step 6: Validate and structure the response
    const result: OpenAIModerationResult = {
      shouldBlock: parsedResponse.shouldBlock || false,
      violationType: parsedResponse.violationType || 'none',
      severity: parsedResponse.severity || 'low',
      confidence: Math.min(Math.max(parsedResponse.confidence || 0, 0), 1), // Clamp between 0-1
      reason: parsedResponse.reason || 'No specific reason provided',
      detectedContent: Array.isArray(parsedResponse.detectedContent) ? parsedResponse.detectedContent : [],
      culturalContext: parsedResponse.culturalContext || undefined,
      processingTime
    };
    
    console.log('âœ… Structured OpenAI Result:', result);
    return result;
    
  } catch (error) {
    console.error('âŒ OpenAI analysis failed:', error);
    
    // Return safe fallback result that triggers manual review
    return {
      shouldBlock: false, // Don't auto-block on errors
      violationType: 'none',
      severity: 'low',
      confidence: 0,
      reason: 'Analysis failed - requires manual review',
      detectedContent: [],
      processingTime: 0
    };
  }
}

/**
 * Main Cloud Function for Message Moderation (Firebase Functions v2)
 */
export const moderateMessage = onDocumentCreated(
  'group_messages/{messageId}',
  async (event) => {
    const functionStartTime = Date.now();
    const messageId = event.params?.messageId;
    const snap = event.data;
    
    if (!snap || !messageId) {
      console.error('âŒ Invalid event data');
      return;
    }
    
    console.log('ğŸš€ MODERATION STARTED for message:', messageId);
    console.log('ğŸ“ Function triggered at:', new Date().toISOString());
    
    try {
      const message = snap.data() as MessageData;
      console.log('ğŸ“ Message data retrieved:', {
        messageId,
        senderCpId: message.senderCpId,
        groupId: message.groupId,
        bodyLength: message.body?.length || 0,
        hasAttachments: !!message.attachments
      });

      // Get user locale for localized responses
      const userLocale = await getUserLocale(message.senderCpId);
      console.log('ğŸŒ User locale:', userLocale);

      // Skip if message has no body
      if (!message.body || message.body.trim().length === 0) {
        console.log('â­ï¸ Skipping moderation - empty message body');
        await snap.ref.update({
          moderation: {
            status: 'approved',
            reason: null
          } as ModerationStatus
        });
        return;
      }

      console.log('ğŸ” Message content preview:', message.body.substring(0, 100) + '...');

      // ============================================
      // ENHANCED MODERATION PIPELINE (8 Steps)
      // ============================================
      
      try {
        const pipelineStartTime = Date.now();

        // Step 1: Normalize Arabic text; keep a char-index map
        console.log('\n=== STEP 1: TEXT NORMALIZATION ===');
        const normalizedResult = normalizeArabicText(message.body);
        console.log('ğŸ“ Original length:', normalizedResult.original.length);
        console.log('ğŸ“ Normalized length:', normalizedResult.normalized.length);

        // Step 2: De-obfuscate common tokens  
        console.log('\n=== STEP 2: TOKEN DE-OBFUSCATION ===');
        const deobfuscatedText = deobfuscateTokens(normalizedResult.normalized);
        console.log('ğŸ” De-obfuscated text preview:', deobfuscatedText.substring(0, 100) + '...');

        // Step 3: Run OpenAI moderation on RAW text
        console.log('\n=== STEP 3: OPENAI ANALYSIS (RAW TEXT) ===');
        const openaiResult = await checkWithOpenAI(message.body); // Use original raw text
        console.log('ğŸ¤– OpenAI result:', {
          shouldBlock: openaiResult.shouldBlock,
          violationType: openaiResult.violationType,
          confidence: openaiResult.confidence
        });

        // Step 4: Apply hard-stop policy using OpenAI scores
        console.log('\n=== STEP 4: HARD-STOP POLICY CHECK ===');
        if (openaiResult.shouldBlock && openaiResult.confidence >= 0.8) {
          console.log('ğŸš« HARD STOP TRIGGERED - Blocking immediately');
          
          const localizedReason = getLocalizedMessage(openaiResult.violationType, userLocale);
          await snap.ref.update({ 
            moderation: {
              status: 'blocked',
              reason: localizedReason
            } as ModerationStatus,
            isHidden: true
          });

          const processingTime = Date.now() - functionStartTime;
          console.log(`ğŸ MODERATION COMPLETED (Hard Stop) in ${processingTime}ms`);
          return;
        }

        // Step 5: Evaluate custom rules on NORMALIZED text
        console.log('\n=== STEP 5: CUSTOM RULE EVALUATION ===');
        const customRuleResults = evaluateCustomRules(deobfuscatedText);
        console.log('ğŸ“Š Custom rules detected:', customRuleResults.length, 'violations');

        // Step 6: Synthesize final decision with precedence
        console.log('\n=== STEP 6: DECISION SYNTHESIS ===');
        const finalDecision = synthesizeDecision(
          openaiResult,
          customRuleResults,
          Date.now() - pipelineStartTime
        );
        console.log('âš–ï¸ Final decision:', finalDecision.action, 'confidence:', finalDecision.confidence);

        // Step 7: Handle redaction spans (if applicable)
        console.log('\n=== STEP 7: REDACTION PROCESSING ===');
        let originalRedactionSpans: Array<{start: number; end: number}> = [];
        
        if (finalDecision.action === 'allow_with_redaction' && finalDecision.redactionSpans) {
          originalRedactionSpans = mapSpansToOriginal(
            finalDecision.redactionSpans,
            normalizedResult.charMap
          );
          console.log('âœï¸ Mapped', finalDecision.redactionSpans.length, 'redaction spans to original text');
        }

        // Step 8: Emit final response with proper status alignment
        console.log('\n=== STEP 8: RESPONSE EMISSION ===');
        
        // Map decision actions to existing status system
        let finalStatus: ModerationStatus['status'] = 'approved';
        let localizedReason: string;
        let shouldHide = false;

        switch (finalDecision.action) {
          case 'block':
            finalStatus = 'blocked';
            shouldHide = true;
            localizedReason = getLocalizedMessage(finalDecision.violationType || 'system_error', userLocale);
            break;
          
          case 'review':
            finalStatus = 'manual_review';
            localizedReason = getLocalizedMessage('manual_review', userLocale);
            break;
          
          case 'allow_with_redaction':
            finalStatus = 'approved'; // Allow but with redaction info
            localizedReason = 'Content approved with redaction';
            break;
          
          case 'allow':
          default:
            finalStatus = 'approved';
            localizedReason = finalDecision.reason;
            break;
        }

        // Update message in database
        const updateData: any = {
          moderation: {
            status: finalStatus,
            reason: localizedReason
          } as ModerationStatus
        };

        if (shouldHide) {
          updateData.isHidden = true;
        }

        // Add redaction data if available (for future use)
        if (originalRedactionSpans.length > 0) {
          updateData.redactionSpans = originalRedactionSpans;
        }

        await snap.ref.update(updateData);
        console.log('âœ… Database updated with final decision');

        // Add to manual review queue if needed
        if (finalStatus === 'manual_review') {
          console.log('ğŸ“‹ Adding to manual review queue...');
          await admin.firestore().collection('moderation_queue').add({
            messageId,
            groupId: message.groupId,
            senderCpId: message.senderCpId,
            messageBody: message.body,
            openaiAnalysis: openaiResult,
            customRuleResults: customRuleResults,
            finalDecision: finalDecision,
            priority: finalDecision.confidence >= 0.7 ? 'high' : 'medium',
            createdAt: admin.firestore.FieldValue.serverTimestamp()
          });
          console.log('âœ… Added to manual review queue');
        }

      } catch (pipelineError) {
        console.error('âŒ Moderation pipeline failed:', pipelineError);
        
        // Fallback to manual review on any pipeline error
        console.log('ğŸ”„ Falling back to manual review due to pipeline failure');
        const fallbackReason = getLocalizedMessage('system_error', userLocale);
        
        await snap.ref.update({
          moderation: {
            status: 'manual_review',
            reason: fallbackReason
          } as ModerationStatus
        });

        // Add to high priority manual review
        await admin.firestore().collection('moderation_queue').add({
          messageId,
          groupId: message.groupId,
          senderCpId: message.senderCpId,
          messageBody: message.body,
          error: (pipelineError as Error).message,
          priority: 'critical',
          createdAt: admin.firestore.FieldValue.serverTimestamp()
        });
      }

      const totalProcessingTime = Date.now() - functionStartTime;
      console.log(`\nğŸ MODERATION COMPLETED in ${totalProcessingTime}ms`);
      console.log('ğŸ“Š Final processing stats:', {
        messageId,
        totalTime: totalProcessingTime,
        pipelineUsed: 'enhanced-8-step',
        openaiModel: 'omni-moderation-2024-09-26',
        stepsCompleted: ['normalization', 'deobfuscation', 'openai_analysis', 'custom_rules', 'decision_synthesis']
      });

    } catch (error) {
      console.error('ğŸ’¥ CRITICAL ERROR in message moderation:', error);
      
      // Log error details
      console.error('Error details:', {
        messageId,
        error: (error as Error).message,
        stack: (error as Error).stack,
        timestamp: new Date().toISOString()
      });

      // Fallback to manual review for any unhandled errors
      try {
        // Get user locale for error message (fallback to arabic if failed)
        let errorLocale: 'arabic' | 'english' = 'arabic';
        try {
          const message = snap.data() as MessageData;
          if (message?.senderCpId) {
            errorLocale = await getUserLocale(message.senderCpId);
          }
        } catch (localeError) {
          console.log('âš ï¸ Could not get user locale for error message, using Arabic');
        }
        
        const errorReason = getLocalizedMessage('system_error', errorLocale);
        
        await snap.ref.update({
          moderation: {
            status: 'manual_review',
            reason: errorReason
          } as ModerationStatus
        });

        // Add to high priority queue
        await admin.firestore().collection('moderation_queue').add({
          messageId,
          error: (error as Error).message,
          priority: 'critical',
          createdAt: admin.firestore.FieldValue.serverTimestamp()
        });

        console.log('ğŸ”„ Error handled: Message sent to manual review');
      } catch (fallbackError) {
        console.error('ğŸ’€ CATASTROPHIC FAILURE: Could not even save error state:', fallbackError);
      }
    }
  });

// Export helper functions for testing
export { 
  checkWithOpenAI,
  detectMessageLanguage,
  normalizeArabicText,
  deobfuscateTokens,
  evaluateCustomRules,
  synthesizeDecision,
  mapSpansToOriginal
};
